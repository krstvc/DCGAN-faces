{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN faces - 128x128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './dataset/celeba-128/'\n",
    "figures_dir = './figures/celeba-128/'\n",
    "checkpoints_dir = './checkpoints/celeba-128/'\n",
    "graphs_dir = './graphs/celeba-128'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 2\n",
    "\n",
    "batch_size = 128\n",
    "image_size = 128\n",
    "\n",
    "nc = 3\n",
    "noise_dim = 100\n",
    "\n",
    "nfg = 64\n",
    "nfd = 64\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "g_learning_rate = 0.0002\n",
    "d_learning_rate = 0.000035\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True if you want to load the model from disk, False if you want the model to be initialized from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up GPU device for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(image_size),\n",
    "                                transforms.CenterCrop(image_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_data = datasets.ImageFolder(dataset_dir, transform=transform)\n",
    "data_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View samples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sample = next(iter(data_loader))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis('off')\n",
    "plt.title('Train data')\n",
    "grid = np.transpose(utils.make_grid(ds_sample[0].to(device)[:64], padding=4, normalize=True).cpu(), (1, 2, 0))\n",
    "plt.imshow(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method for weights initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(model):\n",
    "    if model.__class__.__name__.find('Conv') != -1:\n",
    "        nn.init.normal_(model.weight, 0.0, 0.02)\n",
    "    elif model.__class__.__name__.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(model.weight, 1.0, 0.02)\n",
    "        nn.init.zeros_(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the generator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(noise_dim, nfg*16, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(nfg*16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(nfg*16, nfg*8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(nfg*8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(nfg*8, nfg*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(nfg*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(nfg*4, nfg*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(nfg*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(nfg*2, nfg, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(nfg),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(nfg, nc, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the discriminator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(nc, nfd, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Dropout2d(0.5, inplace=False),\n",
    "            \n",
    "            nn.Conv2d(nfd, nfd*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(nfg*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(nfd*2, nfd*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(nfg*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(nfd*4, nfd*8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(nfg*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(nfd*8, nfd*16, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(nfg*16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Dropout2d(0.5, inplace=False),\n",
    "            \n",
    "            nn.Conv2d(nfd*16, 1, kernel_size=4, stride=2, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the generator and initialize its weights (option 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model == False:\n",
    "    generator = Generator().to(device)\n",
    "    generator.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the discriminator and initialize its weights (option 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model == False:\n",
    "    discriminator = Discriminator().to(device)\n",
    "    discriminator.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from the disk (option 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model == True:\n",
    "    generator = torch.load(os.path.join(checkpoints_dir, 'generator.pt'))\n",
    "    discriminator = torch.load(os.path.join(checkpoints_dir, 'discriminator.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function (BinaryCrossEntropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a noise vector to use to track progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_noise = torch.randn(64, noise_dim, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimizers (Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr=d_learning_rate, betas=(beta1, beta2))\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr=g_learning_rate, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(gen_losses, disc_losses, epoch=None, save=False, show=True):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title('Generator and Discriminator losses')\n",
    "    plt.plot(gen_losses, label='G')\n",
    "    plt.plot(disc_losses, label='D')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(os.path.join(graphs_dir, f'loss_{epoch}.jpg'))\n",
    "    if show == True:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train both networks simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_losses = []\n",
    "disc_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        # Train the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # Fetch the real data\n",
    "        real = data[0].to(device)\n",
    "        size = real.size(0)\n",
    "        \n",
    "        # Init labels as ones for real data\n",
    "        label = torch.full((size,), 1, device=device, dtype=torch.float)\n",
    "        output = discriminator(real).view(-1)\n",
    "        \n",
    "        # Compute loss for real images\n",
    "        disc_err_real = cross_entropy(output, label)\n",
    "        disc_err_real.backward()\n",
    "        real_mean = output.mean().item()\n",
    "        \n",
    "        # Train the discriminator on fake images\n",
    "        noise = torch.randn(size, noise_dim, 1, 1, device=device)\n",
    "        fake = generator(noise)\n",
    "        \n",
    "        # Init labels as zeros for fake data\n",
    "        label.fill_(0)\n",
    "        output = discriminator(fake.detach()).view(-1)\n",
    "        \n",
    "        # Compute loss for fake images\n",
    "        disc_err_fake = cross_entropy(output, label)\n",
    "        disc_err_fake.backward()\n",
    "        fake_mean = output.mean().item()\n",
    "        disc_err = disc_err_real + disc_err_fake\n",
    "        disc_optimizer.step()\n",
    "        \n",
    "        # Train the generator\n",
    "        generator.zero_grad()\n",
    "        \n",
    "        # Init labels as ones\n",
    "        label.fill_(1)\n",
    "        noise = torch.randn(size, noise_dim, 1, 1, device=device)\n",
    "        fake = generator(noise)\n",
    "        output = discriminator(fake).view(-1)\n",
    "        \n",
    "        # Compute generator loss\n",
    "        gen_err = cross_entropy(output, label)\n",
    "        gen_err.backward()\n",
    "        gen_mean = output.mean().item()\n",
    "        gen_optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('[%d/%d][%d/%d] \\tD-Loss:%.4f\\t G-Loss:%.4f\\t D(x):%.4f\\t D(G(z)):%.4f\\t G(z):%.4f' \n",
    "                  % (epoch + 1, epochs, i + 1, len(data_loader), disc_err.item(), gen_err.item(), real_mean, fake_mean, gen_mean))\n",
    "            \n",
    "        gen_losses.append(gen_err.item())\n",
    "        disc_losses.append(disc_err.item())\n",
    "        \n",
    "    end = time.time()\n",
    "    timedelta = datetime.timedelta(seconds=int(end - start))\n",
    "    print(f'Time elapsed for epoch {epoch + 1}: {timedelta}\\n')\n",
    "    with torch.no_grad():\n",
    "        sample = generator(sample_noise).detach().cpu()\n",
    "    grid = np.transpose(utils.make_grid(sample, padding=4, normalize=True).cpu(), (1, 2, 0))\n",
    "    \n",
    "    # Generate samples after every epoch\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(grid)\n",
    "    plt.savefig(os.path.join(figures_dir, f'epoch_{epoch + 1}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        # Generate loss graph\n",
    "        plot_loss(gen_losses, disc_losses, epoch + 1, save=True, show=False)\n",
    "        \n",
    "        # Save progress\n",
    "        torch.save(generator, os.path.join(checkpoints_dir, f'generator.pt'))\n",
    "        torch.save(discriminator, os.path.join(checkpoints_dir, f'discriminator.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear CUDA cache if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(gen_losses, disc_losses, epoch='final', save=True, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate samples on random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(25, noise_dim, 1, 1, device=device).detach()\n",
    "with torch.no_grad():\n",
    "    sample = generator(noise).detach().cpu()\n",
    "grid = np.transpose(utils.make_grid(sample, padding=4, normalize=True, nrow=5).cpu(), (1, 2, 0))\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.axis('off')\n",
    "plt.imshow(grid)\n",
    "# plt.savefig(os.path.join(figures_dir, f'random_{i}.jpg'))\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
